{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\miniconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\lib\\site-packages (2.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement sckit-learn (from versions: none)\n",
      "ERROR: No matching distribution found for sckit-learn\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas sckit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\miniconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\user\\miniconda3\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (2.2.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\miniconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\user\\miniconda3\\lib\\site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\user\\miniconda3\\lib\\site-packages (1.9.4)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from wordcloud) (2.2.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\miniconda3\\lib\\site-packages (from wordcloud) (11.1.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\miniconda3\\lib\\site-packages (from wordcloud) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stopwords in c:\\users\\user\\miniconda3\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import numpy as np        # For numerical operations\n",
    "import pandas as pd       # For data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Importing NLTK for natural language processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')   # Downloading stopwords data\n",
    "nltk.download('punkt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"spam.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Unnamed: 2\",\"Unnamed: 3\",\"Unnamed: 4\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns \n",
    "df.rename(columns={\"v1\":\"target\",\"v2\":'text'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "##data preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['target'] = le.fit_transform(df[\"target\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(403)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop_duplicates(keep='first')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\miniconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\miniconda3\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.data.path.append(\"C:/Users/user/nltk_data\")  # Change this to your actual path\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature engg\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "ps=PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    # Transform the text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization using NLTK\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Removing special characters\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "            \n",
    "    # Removing stop words and punctuation\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    # Loop through the tokens and remove stopwords and punctuation\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "        \n",
    "    # Stemming using Porter Stemmer\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "    \n",
    "    # Join the processed tokens back into a single string\n",
    "    return \" \".join(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\user/nltk_data', 'c:\\\\Users\\\\user\\\\miniconda3\\\\nltk_data', 'c:\\\\Users\\\\user\\\\miniconda3\\\\share\\\\nltk_data', 'c:\\\\Users\\\\user\\\\miniconda3\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\user\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:/Users/user/nltk_data', 'C:/Users/user/nltk_data', 'D:\\\\nltk_data', 'C:/Users/user/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"C:/Users/user/nltk_data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go jurong point crazi avail bugi n great world la e buffet cine got amor wat'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_text('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri 2 wkli comp win fa cup final tkt 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say earli hor u c alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                    transformed_text  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                              ok lar joke wif u oni  \n",
       "2  free entri 2 wkli comp win fa cup final tkt 21...  \n",
       "3                u dun say earli hor u c alreadi say  \n",
       "4               nah think goe usf live around though  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "tfidf=TfidfVectorizer(max_features=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.0-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\miniconda3\\lib\\site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\miniconda3\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Downloading xgboost-3.0.0-py3-none-win_amd64.whl (150.0 MB)\n",
      "   ---------------------------------------- 0.0/150.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/150.0 MB 12.0 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 5.0/150.0 MB 14.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 7.3/150.0 MB 12.9 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 9.7/150.0 MB 12.3 MB/s eta 0:00:12\n",
      "   --- ------------------------------------ 11.3/150.0 MB 11.4 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 12.3/150.0 MB 10.3 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 12.8/150.0 MB 10.1 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 14.4/150.0 MB 8.8 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 15.7/150.0 MB 8.5 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 17.0/150.0 MB 8.3 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 18.9/150.0 MB 8.3 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 19.9/150.0 MB 8.3 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 21.8/150.0 MB 8.1 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 23.1/150.0 MB 7.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 24.4/150.0 MB 7.8 MB/s eta 0:00:17\n",
      "   ------ --------------------------------- 25.7/150.0 MB 7.7 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 27.0/150.0 MB 7.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 28.0/150.0 MB 7.5 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 29.4/150.0 MB 7.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 30.9/150.0 MB 7.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 32.2/150.0 MB 7.3 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 33.6/150.0 MB 7.3 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 34.6/150.0 MB 7.2 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 35.9/150.0 MB 7.1 MB/s eta 0:00:17\n",
      "   --------- ------------------------------ 37.0/150.0 MB 7.0 MB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 38.3/150.0 MB 7.0 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 39.6/150.0 MB 7.0 MB/s eta 0:00:16\n",
      "   ---------- ----------------------------- 41.2/150.0 MB 7.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 42.7/150.0 MB 7.0 MB/s eta 0:00:16\n",
      "   ----------- ---------------------------- 44.3/150.0 MB 7.0 MB/s eta 0:00:16\n",
      "   ------------ --------------------------- 45.6/150.0 MB 7.0 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 46.7/150.0 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------ --------------------------- 48.0/150.0 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 49.3/150.0 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 50.6/150.0 MB 6.9 MB/s eta 0:00:15\n",
      "   ------------- -------------------------- 51.9/150.0 MB 6.8 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 53.5/150.0 MB 6.9 MB/s eta 0:00:15\n",
      "   -------------- ------------------------- 54.8/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   -------------- ------------------------- 56.1/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 57.1/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   --------------- ------------------------ 58.5/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 60.0/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 61.1/150.0 MB 6.8 MB/s eta 0:00:14\n",
      "   ---------------- ----------------------- 62.4/150.0 MB 6.8 MB/s eta 0:00:13\n",
      "   ---------------- ----------------------- 63.7/150.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 65.0/150.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ----------------- ---------------------- 66.3/150.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 67.9/150.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 69.2/150.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------ --------------------- 70.5/150.0 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 71.8/150.0 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 73.1/150.0 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------- -------------------- 74.7/150.0 MB 6.7 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 75.8/150.0 MB 6.6 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 77.1/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   -------------------- ------------------- 78.4/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 80.0/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 81.0/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 82.3/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 83.6/150.0 MB 6.6 MB/s eta 0:00:11\n",
      "   ---------------------- ----------------- 84.9/150.0 MB 6.6 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 85.2/150.0 MB 6.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 86.2/150.0 MB 6.5 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 87.8/150.0 MB 6.5 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 90.2/150.0 MB 6.6 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 91.8/150.0 MB 6.6 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 93.1/150.0 MB 6.6 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 94.4/150.0 MB 6.6 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 95.7/150.0 MB 6.6 MB/s eta 0:00:09\n",
      "   ------------------------- -------------- 97.0/150.0 MB 6.5 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 98.3/150.0 MB 6.5 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 99.6/150.0 MB 6.5 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 100.9/150.0 MB 6.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 102.2/150.0 MB 6.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 103.5/150.0 MB 6.5 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 104.9/150.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 106.2/150.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 107.5/150.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 108.5/150.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 110.1/150.0 MB 6.5 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 111.4/150.0 MB 6.5 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 112.5/150.0 MB 6.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 114.0/150.0 MB 6.5 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 115.3/150.0 MB 6.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 116.7/150.0 MB 6.5 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 118.0/150.0 MB 6.5 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 119.3/150.0 MB 6.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 120.6/150.0 MB 6.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 121.9/150.0 MB 6.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 123.2/150.0 MB 6.5 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 124.5/150.0 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 125.8/150.0 MB 6.5 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 127.1/150.0 MB 6.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 128.5/150.0 MB 6.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 129.8/150.0 MB 6.5 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 131.1/150.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 132.6/150.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 133.7/150.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 135.0/150.0 MB 6.5 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 136.6/150.0 MB 6.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 137.9/150.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 138.9/150.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 140.5/150.0 MB 6.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 141.6/150.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 142.9/150.0 MB 6.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 144.2/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 145.5/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  147.1/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.4/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  148.9/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.7/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  149.9/150.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 150.0/150.0 MB 6.3 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model training \n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9294003868471954\n",
      "[[887   2]\n",
      " [ 71  74]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96       889\n",
      "           1       0.97      0.51      0.67       145\n",
      "\n",
      "    accuracy                           0.93      1034\n",
      "   macro avg       0.95      0.75      0.82      1034\n",
      "weighted avg       0.93      0.93      0.92      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knc = KNeighborsClassifier()\n",
    "knc.fit(X_train,y_train)\n",
    "y_pred = knc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9758220502901354\n",
      "[[887   2]\n",
      " [ 23 122]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       889\n",
      "           1       0.98      0.84      0.91       145\n",
      "\n",
      "    accuracy                           0.98      1034\n",
      "   macro avg       0.98      0.92      0.95      1034\n",
      "weighted avg       0.98      0.98      0.98      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train,y_train)\n",
    "y_pred = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9313346228239845\n",
      "[[870  19]\n",
      " [ 52  93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       889\n",
      "           1       0.83      0.64      0.72       145\n",
      "\n",
      "    accuracy                           0.93      1034\n",
      "   macro avg       0.89      0.81      0.84      1034\n",
      "weighted avg       0.93      0.93      0.93      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth = 5)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred=dtc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.971953578336557\n",
      "[[885   4]\n",
      " [ 25 120]]\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 50, random_state=2)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9129593810444874\n",
      "[[869  20]\n",
      " [ 70  75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       889\n",
      "           1       0.79      0.52      0.62       145\n",
      "\n",
      "    accuracy                           0.91      1034\n",
      "   macro avg       0.86      0.75      0.79      1034\n",
      "weighted avg       0.91      0.91      0.91      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(n_estimators = 50, random_state = 2)\n",
    "abc.fit(X_train,y_train)\n",
    "y_pred = abc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9584139264990329\n",
      "[[871  18]\n",
      " [ 25 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       889\n",
      "           1       0.87      0.83      0.85       145\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.92      0.90      0.91      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bc = BaggingClassifier(n_estimators = 50, random_state = 2)\n",
    "bc.fit(X_train,y_train)\n",
    "y_pred = bc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777562862669246\n",
      "[[881   8]\n",
      " [ 15 130]]\n",
      "<function classification_report at 0x00000235AAB47D80>\n"
     ]
    }
   ],
   "source": [
    "etc = ExtraTreesClassifier(n_estimators = 50, random_state = 2)\n",
    "etc.fit(X_train,y_train)\n",
    "y_pred = etc.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9516441005802708\n",
      "[[884   5]\n",
      " [ 45 100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       889\n",
      "           1       0.95      0.69      0.80       145\n",
      "\n",
      "    accuracy                           0.95      1034\n",
      "   macro avg       0.95      0.84      0.89      1034\n",
      "weighted avg       0.95      0.95      0.95      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbdt = GradientBoostingClassifier(n_estimators = 50, random_state = 2)    \n",
    "gbdt.fit(X_train,y_train)\n",
    "y_pred = gbdt.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9680851063829787\n",
      "[[882   7]\n",
      " [ 26 119]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       889\n",
      "           1       0.94      0.82      0.88       145\n",
      "\n",
      "    accuracy                           0.97      1034\n",
      "   macro avg       0.96      0.91      0.93      1034\n",
      "weighted avg       0.97      0.97      0.97      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb  = XGBClassifier(n_estimators = 50, random_state = 2)\n",
    "xgb.fit(X_train,y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
